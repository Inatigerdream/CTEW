{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for model statistics\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # DATA # # #\n",
    "# load iris flower data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split data into train and test sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=.33, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS DATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3\n",
       "count  150.000000  150.000000  150.000000  150.000000\n",
       "mean     5.843333    3.054000    3.758667    1.198667\n",
       "std      0.828066    0.433594    1.764420    0.763161\n",
       "min      4.300000    2.000000    1.000000    0.100000\n",
       "25%      5.100000    2.800000    1.600000    0.300000\n",
       "50%      5.800000    3.000000    4.350000    1.300000\n",
       "75%      6.400000    3.300000    5.100000    1.800000\n",
       "max      7.900000    4.400000    6.900000    2.500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"IRIS DATA\")\n",
    "pd.DataFrame(x).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS TARGET DATA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  150.000000\n",
       "mean     1.000000\n",
       "std      0.819232\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      2.000000\n",
       "max      2.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('IRIS TARGET DATA')\n",
    "pd.DataFrame(y).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# Cross Validation\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "# how to use\n",
    "# use part of a table as index\n",
    "irisdata = pd.DataFrame(iris.data).reset_index()\n",
    "xtrain, xtest = split_train_test_by_id(irisdata, 0.2, 'index')\n",
    "irisdata2 = pd.DataFrame(iris.target).reset_index()\n",
    "ytrain, ytest = split_train_test_by_id(irisdata2, 0.2, 'index')\n",
    "\n",
    "ytrain = ytrain.iloc[:,1:]\n",
    "xtrain = xtrain.iloc[:,1:]\n",
    "ytest = ytest.iloc[:,1:]\n",
    "xtest = xtest.iloc[:,1:]\n",
    "\n",
    "\n",
    "# print('xtest_size:', test_set.shape[0], '\\nxtrain_size:', train_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Scores\n",
      "  Accuracy: 92.85714285714286%\n",
      "  Loss: 0.07142857142857142\n",
      "\n",
      "Feature Importance\n",
      "   sepal length (cm) :\t 0.01\n",
      "   sepal width (cm) :\t 0.0\n",
      "   petal length (cm) :\t 0.33\n",
      "   petal width (cm) :\t 0.65\n"
     ]
    }
   ],
   "source": [
    "# # # DECISION TREE # # #\n",
    "from sklearn import tree\n",
    "\n",
    "#create tree object\n",
    "# algorithms are gini or entropy\n",
    "model1 = tree.DecisionTreeClassifier(criterion='entropy') # entropy tends to produce more balanced trees\n",
    "\n",
    "# x(predictor) y(target) x_test(predictor) of test_dataset\n",
    "model1.fit(xtrain, ytrain)\n",
    "# model1.score(x, y)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred1 = model1.predict(xtest)\n",
    "predictions1 = [round(v) for v in y_pred1]\n",
    "ac1 = accuracy_score(ytest, predictions1)\n",
    "loss1 = hamming_loss(ytest, predictions1)\n",
    "print(\"Model Scores\")\n",
    "print(\"  Accuracy: {}%\".format(ac1*100.0))\n",
    "print(\"  Loss: {}\".format(loss1))\n",
    "\n",
    "# feature imporance\n",
    "print('\\nFeature Importance')\n",
    "for name, score in zip(iris['feature_names'], model1.feature_importances_):\n",
    "    print(\"  \", name, ':\\t', round(score, 2))\n",
    "\n",
    "# # visualize decision tree\n",
    "# # to convert dot file to png on terminal:$ dot tree.dot -Tpng -o tree.png\n",
    "# from sklearn.tree import export_graphviz\n",
    "\n",
    "# export_graphviz(\n",
    "#     model,\n",
    "#     out_file=\"/home/rlougee/Desktop/iris_tree.dot\",\n",
    "#     feature_names=iris.feature_names[2:],\n",
    "#     class_names=iris.target_names,\n",
    "#     rounded=True,\n",
    "#     filled=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlougee/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Scores\n",
      "  Accuracy: 93.0%\n",
      "  Loss: 0.07\n",
      "\n",
      "Feature Importance\n",
      "   sepal length (cm) :\t 0.09\n",
      "   sepal width (cm) :\t 0.02\n",
      "   petal length (cm) :\t 0.46\n",
      "   petal width (cm) :\t 0.43\n"
     ]
    }
   ],
   "source": [
    "# # # RANDOM FOREST # # #\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create random forest object\n",
    "model2 = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Train the model using the training sets and check score\n",
    "model2.fit(xtrain, ytrain)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred2 = model2.predict(xtest)\n",
    "predictions2 = [round(v) for v in y_pred2]\n",
    "ac2 = accuracy_score(ytest, predictions2)\n",
    "loss2 = hamming_loss(ytest, predictions2)\n",
    "print(\"Model Scores\")\n",
    "print(\"  Accuracy: {}%\".format(round(ac2*100.0),2))\n",
    "print(\"  Loss: {}\".format(round(loss2, 2)))\n",
    "\n",
    "# feature imporance\n",
    "print('\\nFeature Importance')\n",
    "for name, score in zip(iris['feature_names'], model2.feature_importances_):\n",
    "    print(\"  \", name, ':\\t', round(score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlougee/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Scores\n",
      "  Accuracy: 92.86%\n",
      "  Loss: 0.07\n",
      "\n",
      "Feature Importance\n",
      "   sepal length (cm) :\t 0.03\n",
      "   sepal width (cm) :\t 0.19\n",
      "   petal length (cm) :\t 0.16\n",
      "   petal width (cm) :\t 0.13\n"
     ]
    }
   ],
   "source": [
    "# # # GBM # # #\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.ensemble import GradientBoostingRegression\n",
    "\n",
    "# create GBM object\n",
    "model3 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "\n",
    "# train the model\n",
    "model3.fit(xtrain, ytrain)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred3 = model3.predict(xtest)\n",
    "predictions3 = [round(v) for v in y_pred3]\n",
    "ac3 = accuracy_score(ytest, predictions3)\n",
    "loss3 = hamming_loss(ytest, predictions3)\n",
    "print(\"Model Scores\")\n",
    "print(\"  Accuracy: {}%\".format(round(ac3*100.0, 2)))\n",
    "print(\"  Loss: {}\".format(round(loss3, 2)))\n",
    "\n",
    "# feature imporance\n",
    "print('\\nFeature Importance')\n",
    "for name, score in zip(iris['feature_names'], model3.feature_importances_):\n",
    "    print(\"  \", name, ':\\t', round(score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Scores\n",
      "Accuracy: 100.0%\n",
      "Loss: 0.0\n",
      "\n",
      "Feature Importance\n",
      "   sepal length (cm) :\t 0.18\n",
      "   sepal width (cm) :\t 0.11\n",
      "   petal length (cm) :\t 0.41\n",
      "   petal width (cm) :\t 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlougee/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# # # XGBOOST # # #\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# create XGB model\n",
    "model4 = XGBClassifier()\n",
    "\n",
    "# train XGB model\n",
    "model4.fit(x, y)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred4 = model4.predict(xtest)\n",
    "predictions4 = [round(v) for v in y_pred4]\n",
    "ac4 = accuracy_score(ytest, predictions4)\n",
    "loss4 = hamming_loss(ytest, predictions4)\n",
    "print(\"Model Scores\")\n",
    "print(\"Accuracy: {}%\".format(ac4*100.0))\n",
    "print(\"Loss: {}\".format(loss4))\n",
    "\n",
    "# feature imporance\n",
    "print('\\nFeature Importance')\n",
    "for name, score in zip(iris['feature_names'], model4.feature_importances_):\n",
    "\n",
    "    print(\"  \", name, ':\\t', round(score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # PARAMETER TUNING # # #\n",
    "# 1) choose high learning rate\n",
    "    # (0.05 - 0.30) generally 0.10 works\n",
    "    # AND determine optimum number of tress (xgboost cv)\n",
    "# 2) tune tree-specific parameters\n",
    "    # max_depth (3-10) 5 is good\n",
    "    # min_child_weight 1\n",
    "    # gamma (0.1 and 0.2 are ok) 0\n",
    "    # subsample, colsample_bytree (0.5-0.9) 0.8\n",
    "    # scale_pos_weight 1\n",
    "# 3) tune regularization parameters\n",
    "    # lambda, alpha\n",
    "# 4) lower learning rate and decide on optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # CV FUNCTION # # #\n",
    "\n",
    "def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob))\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBFeatureImportances(predictors)\n",
    "clf.fit(xgb1, train)\n",
    "importances = clf.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}